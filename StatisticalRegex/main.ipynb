{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "This is a neat project I made as POC for a client. Client was dealing with very dirty data in a sql db, basically every column was a string/varchar. we needed a way to sniff out patterns. Client had tried numerous tools, but all were very slow. billion+ rows, per table, per db. :/\n",
    "\n",
    "I used a kind of broken makarov chain to generate a pattern of the data, like the reverse of a regex. For example, if a column was a list of ID's, that looked like:\n",
    "m1234\n",
    "m9876576a35\n",
    "m34987\n",
    "m340598\n",
    "we see a pattern like M[number][number][number]. M always appears first, but after that its about 4 or so \n",
    "random numbers. \n",
    "\n",
    "While not the most thorough model, it was more than sufficient when combined with internal domain knowledge to start standing up better documentation. For instance.... if an unknown column came back with a pattern of a[number][number]9, the super users knew this was a document ID for some fax system. I had no clue, but it helped them immensely to figure out what database tables had what data at a quick glance. Given the speed of the algo, it could be ran on lots of stuff, quickly. \n",
    "\n",
    "This is NOT the final version. This is like, a working session version, stumbling through the ask."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b058911a8cfcf96f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from dateutil.parser import parse"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e1a3d5517b2e5b8a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "meteordf = pd.read_csv('Meteorite_Landings.csv')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7da06f5fe354be59"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for x,y in meteordf.dtypes.items():\n",
    "    print(x,y)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "81bd21b97be3b0d3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "setup our resulting data frame"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1f4d76902fb8ad51"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dftypes = pd.DataFrame(meteordf.dtypes.items())\n",
    "dftypes.rename(columns={ dftypes.columns[0]: \"column_name\", dftypes.columns[1]: \"column_type\" }, inplace = True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6792ded5accde99e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dftypes = dftypes.assign(**{'column_agg_type' : 'Pandas Detection' ,  'value_desc' : 'Pandas Inferred Data Type From Load'})"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "22eb7de8c9a37d2d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#variable setup\n",
    "alphabet = string.ascii_letters+string.punctuation\n",
    "\n",
    "\n",
    "#make copy of data\n",
    "recordsdf = meteordf.copy(deep=True)\n",
    "\n",
    "#attempt to convert everything to a string, sorta helps\n",
    "all_columns = list(recordsdf)\n",
    "recordsdf[all_columns] = recordsdf[all_columns].astype(str).replace('nan',np.nan)\n",
    "\n",
    "#record list of column names\n",
    "generated_column_names = []\n",
    "\n",
    "#aggregated_features_df = pd.DataFrame(columns=['column_name', 'column_agg_type', 'value', 'value_desc'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "74bb43cfc1eab88e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "start with a ton of defintions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f8c067a98793f7bf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "#pandas series checks don't include floats\n",
    "#need to make a function that does this for us\n",
    "def is_float(x):\n",
    "    try:\n",
    "        float(x)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "#pandas has no datetime checker in series methods\n",
    "#almost any float will come back as true    \n",
    "def is_date(x):\n",
    "    try:\n",
    "        parse(x)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "#this is used to try to find a pattern in the column\n",
    "#assumes most entries are close in look\n",
    "#will miss patterns if left of string differs\n",
    "\n",
    "def is_pattern(x):\n",
    "\n",
    "    pattern_list=[]\n",
    "\n",
    "    try:\n",
    "        pattern_df = x.astype(str).apply(lambda x: pd.Series(list(x)))\n",
    "\n",
    "\n",
    "        pattern_df.dropna(axis='columns', inplace=True)\n",
    "\n",
    "        n = pd.DataFrame(pattern_df.nunique(axis=0, dropna=True), columns=['count'])\n",
    "\n",
    "        actualpattern_df = n.loc[n['count'] == 1]\n",
    "\n",
    "\n",
    "        for x,y in actualpattern_df.iterrows():\n",
    "            string = \"{} is repeated in position {}\".format(pattern_df[x].iloc[0],x)\n",
    "            pattern_list.append(string)\n",
    "\n",
    "        if not pattern_list:\n",
    "            pattern_list.append('none')\n",
    "\n",
    "        return(pattern_list)\n",
    "\n",
    "    except:\n",
    "        pattern_list.append('none')\n",
    "        return(pattern_list)\n",
    "\n",
    "\n",
    "\n",
    "def statistical_generative_regex(c):\n",
    "\n",
    "    def add_raw_char(currentcolumnkey, currentchar):\n",
    "        if attribdct[currentcolumnkey]['raw'].get(currentchar) is None:\n",
    "            attribdct[currentcolumnkey]['raw'][currentchar]=1\n",
    "        else:\n",
    "            attribdct[currentcolumnkey]['raw'][currentchar] = attribdct[currentcolumnkey]['raw'][currentchar] + 1\n",
    "\n",
    "    length = 0\n",
    "    totallength = 0\n",
    "    count = 0\n",
    "    lengthls = []\n",
    "\n",
    "    for x in c:\n",
    "        length = len(str(x))\n",
    "        totallength = totallength + length\n",
    "        count = count + 1\n",
    "        lengthls.append(length)\n",
    "\n",
    "    #print(np.median(lengthls))\n",
    "\n",
    "    medianrecordsdf = c[c.astype(str).map(len) == np.ceil(np.median(lengthls))]\n",
    "\n",
    "    #print(medianrecordsdf)\n",
    "\n",
    "\n",
    "    medianrecordsdf = medianrecordsdf.astype(str).replace('nan', \"\")\n",
    "    medianrecordsdf = medianrecordsdf.astype(str).replace(np.nan, \"\")\n",
    "\n",
    "    pattern_df = medianrecordsdf.astype(str).apply(lambda x: pd.Series(list(x)))\n",
    "    all_columns = list(pattern_df)\n",
    "    #pattern_df[all_columns] = pattern_df[all_columns].astype(str).replace(\"\", 'null')\n",
    "    #pattern_df[all_columns] = pattern_df[all_columns].astype(str).replace(np.nan, 'null')\n",
    "\n",
    "    for cols in all_columns:\n",
    "        #pattern_df[cols] = pattern_df[cols].astype(str).replace('', 'null')\n",
    "        pattern_df[cols].mask(pattern_df[cols].astype(str) == '', 'null', inplace=True)\n",
    "        pattern_df[cols].mask(pattern_df[cols].astype(str) == np.nan, 'null', inplace=True)\n",
    "        pattern_df[cols].mask(pattern_df[cols].astype(str) == 'nan', 'null', inplace=True)\n",
    "        pattern_df[cols].mask(pattern_df[cols].astype(str).isnull() == True, 'null', inplace=True)\n",
    "        pattern_df[cols].fillna('null', inplace=True)\n",
    "\n",
    "\n",
    "    rowcount = len(pattern_df.index)\n",
    "\n",
    "    alpha = 0\n",
    "    digit = 0\n",
    "    special = 0\n",
    "    null = 0\n",
    "    space = 0\n",
    "    unknown = 0\n",
    "    unknownls = []\n",
    "    attribdct = {}\n",
    "\n",
    "    for x in pattern_df.columns:\n",
    "        #print(x)\n",
    "\n",
    "        attribdct[x] = {'agg': {} , 'raw':{}}\n",
    "\n",
    "        alpha = 0\n",
    "        digit = 0\n",
    "        special = 0\n",
    "        null = 0\n",
    "        space = 0\n",
    "        unknown = 0\n",
    "        for y in pattern_df[x]:\n",
    "            #print(type(y))\n",
    "            if y =='null':\n",
    "                null = null + 1\n",
    "                add_raw_char(x,y)\n",
    "            elif y.isalpha():\n",
    "                alpha = alpha+1\n",
    "                add_raw_char(x,y)\n",
    "            elif y.isdigit():\n",
    "                digit = digit+1\n",
    "                add_raw_char(x,y)\n",
    "            elif y in string.punctuation:\n",
    "                special = special + 1\n",
    "                add_raw_char(x,y)\n",
    "            elif y.isspace():\n",
    "                space = space + 1\n",
    "                add_raw_char(x,y)\n",
    "            else:\n",
    "                unknown = unknown + 1\n",
    "                unknownls.append(y)\n",
    "                add_raw_char(x,y)\n",
    "\n",
    "\n",
    "        #print('Column {}; alpha:{} digit:{} special:{} null:{} space:{} unknown:{} '.format(x, alpha, digit, special, null, space, unknown))\n",
    "\n",
    "\n",
    "        attribdct[x]['agg'] = {'alpha': alpha, 'digit': digit, 'special': special, 'null': null, 'space': space, 'unknown': unknown}\n",
    "\n",
    "    outputholder = []\n",
    "    for z in attribdct:\n",
    "        charposition = max(attribdct[z]['agg'], key=attribdct[z]['agg'].get)\n",
    "        charvalue = max(attribdct[z]['raw'], key=attribdct[z]['raw'].get)\n",
    "        chardesc = charposition\n",
    "        if attribdct[z]['raw'][charvalue]/rowcount > .90:\n",
    "            chardesc = charvalue\n",
    "\n",
    "        formatedchardesc = '[{}]'.format(chardesc)\n",
    "\n",
    "        outputholder.append(formatedchardesc)\n",
    "\n",
    "    #print('position {} was a {}'.format(z, position ))\n",
    "\n",
    "    patternholder = \"\"\n",
    "\n",
    "    for chars in outputholder:\n",
    "        patternholder = patternholder + chars\n",
    "\n",
    "    return patternholder\n",
    "    #print(*outputholder)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2b8825c272121a89"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "#loop each column and run battery of tests\n",
    "cols_to_iterate = recordsdf.columns\n",
    "ls = []\n",
    "for x in cols_to_iterate:\n",
    "    print(x)\n",
    "\n",
    "    \n",
    "    #pull pandas type find\n",
    "    type_dict = {\n",
    "        'column_name' : x,\n",
    "        'column_agg_type':  'Pandas Detection',\n",
    "        'value' : dftypes.loc[dftypes['column_name'] == x][:1]['column_type'].item().name,\n",
    "        'value_desc' : 'Pandas Inferred Data Type From Load'\n",
    "    }\n",
    "    \n",
    "    ls.append(type_dict)\n",
    "\n",
    "    #is alpha test\n",
    "    newcolumnname = x + '_is_alpha'\n",
    "    recordsdf[newcolumnname] = recordsdf[x].str.isalpha()\n",
    "    recordsdf[newcolumnname].fillna(False, inplace = True)\n",
    "\n",
    "    alpha_dict = {'column_name': x , 'column_agg_type' : 'isalpha' , 'value': recordsdf[newcolumnname].mean(), 'value_desc' : \"% True\"}\n",
    "    #aggregated_features_df[x]['alpha'] = recordsdf[newcolumnname].mean()\n",
    "    \n",
    "    ls.append(alpha_dict)\n",
    "\n",
    "    #is alphanumeric test\n",
    "    newcolumnname = x + '_is_alphanumeric'\n",
    "    recordsdf[newcolumnname] = recordsdf[x].str.isalnum()\n",
    "    recordsdf[newcolumnname].fillna(False, inplace = True)\n",
    "    \n",
    "    numeric_dict = {'column_name': x , 'column_agg_type' : 'isalphanumeric' , 'value': recordsdf[newcolumnname].mean(), 'value_desc' : \"% True\"}\n",
    "\n",
    "    ls.append(numeric_dict)\n",
    "\n",
    "    #is_didigt test\n",
    "    newcolumnname = x + '_is_digit'\n",
    "    recordsdf[newcolumnname] = recordsdf[x].str.isdigit()\n",
    "    recordsdf[newcolumnname].fillna(False, inplace = True)\n",
    "    \n",
    "    digit_dict = {'column_name': x , 'column_agg_type' : 'isdigit' , 'value': recordsdf[newcolumnname].mean(), 'value_desc' : \"% True\"}\n",
    "    \n",
    "    ls.append(digit_dict)\n",
    "\n",
    "    #is space test\n",
    "    newcolumnname = x + '_is_space'\n",
    "    recordsdf[newcolumnname] = recordsdf[x].str.isspace()\n",
    "    recordsdf[newcolumnname].fillna(False, inplace = True)\n",
    "    \n",
    "    space_dict = {'column_name': x , 'column_agg_type' : 'isspace' , 'value': recordsdf[newcolumnname].mean(), 'value_desc' : \"% True\"}\n",
    "    \n",
    "    ls.append(space_dict)\n",
    "\n",
    "    # is lower test\n",
    "    newcolumnname = x + '_is_lower'\n",
    "    recordsdf[newcolumnname] = recordsdf[x].str.islower()\n",
    "    recordsdf[newcolumnname].fillna(False, inplace = True)\n",
    "    \n",
    "    lower_dict = {'column_name': x , 'column_agg_type' : 'islower' , 'value': recordsdf[newcolumnname].mean(), 'value_desc' : \"% True\"}\n",
    "    \n",
    "    ls.append(lower_dict)\n",
    "\n",
    "    #is upper test\n",
    "    newcolumnname = x + '_is_upper'\n",
    "    recordsdf[newcolumnname] = recordsdf[x].str.isupper()\n",
    "    recordsdf[newcolumnname].fillna(False, inplace = True)\n",
    " \n",
    "    upper_dict = {'column_name': x , 'column_agg_type' : 'isupper' , 'value': recordsdf[newcolumnname].mean(), 'value_desc' : \"% True\"}\n",
    "\n",
    "    #numeric test\n",
    "    newcolumnname = x + '_is_numeric'\n",
    "    recordsdf[newcolumnname] = recordsdf[x].str.isnumeric()\n",
    "    recordsdf[newcolumnname].fillna(False, inplace = True)\n",
    "    \n",
    "    numerical_dict = {'column_name': x , 'column_agg_type' : 'isnumeric' , 'value': recordsdf[newcolumnname].mean(), 'value_desc' : \"% True\"}\n",
    "    ls.append(numerical_dict)\n",
    "\n",
    "    #decimal test\n",
    "    newcolumnname = x + '_is_decimal'\n",
    "    recordsdf[newcolumnname] = recordsdf[x].str.isdecimal()\n",
    "    recordsdf[newcolumnname].fillna(False, inplace = True)\n",
    "    decimal_dict = {'column_name': x , 'column_agg_type' : 'isdecimal' , 'value': recordsdf[newcolumnname].mean(), 'value_desc' : \"% True\"}\n",
    "    ls.append(numerical_dict)\n",
    "\n",
    "    #trying float logic\n",
    "    newcolumnname = x + '_is_float'\n",
    "    recordsdf[newcolumnname] = recordsdf[x].apply(is_float)\n",
    "    recordsdf[newcolumnname].fillna(False, inplace = True)\n",
    "    float_dict = {'column_name': x , 'column_agg_type' : 'isfloat' , 'value': recordsdf[newcolumnname].mean(), 'value_desc' : \"% True\"}\n",
    "    ls.append(float_dict)\n",
    "\n",
    "\n",
    "    #trying date logic\n",
    "    newcolumnname = x + '_is_date'\n",
    "    recordsdf[newcolumnname] = recordsdf[x].apply(is_date)\n",
    "    recordsdf[newcolumnname].fillna(False, inplace = True)\n",
    "    \n",
    "    date_dict = {'column_name': x , 'column_agg_type' : 'isdate' , 'value': recordsdf[newcolumnname].mean(), 'value_desc' : \"% True(High False Postive)\"}\n",
    "    ls.append(date_dict)\n",
    "\n",
    "\n",
    "    #special character test\n",
    "    newcolumnname = x + '_is_specialcharacters'\n",
    "    recordsdf[newcolumnname] = recordsdf[x].str.strip(alphabet).astype(bool)\n",
    "    special_char_test = {'column_name': x , 'column_agg_type' : 'isspecialcharacters' , 'value': recordsdf[newcolumnname].mean(), 'value_desc' : \"% True\"}\n",
    "    ls.append(special_char_test)\n",
    "\n",
    "    #is_na test\n",
    "    newcolumnname = x + '_is_na'\n",
    "    recordsdf[newcolumnname] = recordsdf[x].isnull()\n",
    "    recordsdf[newcolumnname].fillna(False, inplace = True)\n",
    "    \n",
    "    na_dict = {'column_name': x , 'column_agg_type' : 'isna' , 'value': recordsdf[newcolumnname].mean(), 'value_desc' : \"% True\"}\n",
    "    ls.append(na_dict)\n",
    "\n",
    "    #min test\n",
    "    newcolumnname = x + '_min'\n",
    "    recordsdf[newcolumnname] = recordsdf[x].astype('string').min()\n",
    "    recordsdf[newcolumnname].fillna(False, inplace = True)\n",
    "    \n",
    "    min_dict = {'column_name': x , 'column_agg_type' : 'min' , 'value': recordsdf[newcolumnname].iloc[0], 'value_desc' : \"min\"}\n",
    "    ls.append(min_dict)\n",
    "\n",
    "    #max test\n",
    "    newcolumnname = x + '_max'\n",
    "    recordsdf[newcolumnname] = recordsdf[x].astype('string').max()\n",
    "    recordsdf[newcolumnname].fillna(False, inplace = True)\n",
    "    max_dict = {'column_name': x , 'column_agg_type' : 'max' , 'value': recordsdf[newcolumnname].iloc[0], 'value_desc' : \"max\"}\n",
    "    ls.append(max_dict)\n",
    "\n",
    "    #statistical\n",
    "    newcolumnname = x + '_statistical regex'\n",
    "    pattern_return = statistical_generative_regex(recordsdf[x])\n",
    "    recordsdf[newcolumnname] = str(pattern_return)\n",
    "    recordsdf[newcolumnname].fillna(False, inplace = True)\n",
    "    \n",
    "    stat_dict = {'column_name': x , 'column_agg_type' : 'statistical_regex' , 'value': recordsdf[newcolumnname].iloc[0], 'value_desc' : \"list\"}\n",
    "    ls.append(stat_dict)\n",
    "    \n",
    "    \n",
    "        \n",
    "    \n",
    "aggregated_features_df = pd.DataFrame(ls)\n",
    "    \n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d0b6d2d2535523b1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
